{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e588c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import clip\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import *\n",
    "from deepfashion_loader import *\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e83459",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "# Configuration params\n",
    "cfg = {'root'                : '../ifetch',\n",
    "       'arch'                : 'resnet50',\n",
    "       'train_dict_path'     : './preprocessed/deepfashion_inshop_train.pt',\n",
    "       'train_features_path' : None, #'./preprocessed/deepfashion_inshop_train_' + 'resnet50' + '.pt',\n",
    "       'dev_dict_path'       : './preprocessed/deepfashion_inshop_val.pt',\n",
    "       'dev_features_path'   : None, #'./preprocessed/deepfashion_inshop_val_' + 'resnet50' + '.pt',\n",
    "       'taxonomy_path'       : './deepfashion_taxonomy_hyperbolic.pt',\n",
    "       'bbox_path'           : '../ifetch/deepfashion/in_shop/list_bbox_inshop.txt',\n",
    "       'batch_size'          : 1024}\n",
    "\n",
    "data_T = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "samples = DeepFashionData(root=cfg['root'],\n",
    "                          data_dict_path=cfg['dev_dict_path'],\n",
    "                          features_path=cfg['dev_features_path'],\n",
    "                          taxonomy_path=cfg['taxonomy_path'],\n",
    "                          transforms=data_T,\n",
    "                          bbox_path=cfg['bbox_path'])\n",
    "\n",
    "loader = DataLoader(samples,\n",
    "                    batch_size=cfg['batch_size'],\n",
    "                    shuffle=False,\n",
    "                    collate_fn=samples.collate_fn)\n",
    "\n",
    "model = HyperbolicFeat()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./exp_hyperbolic_2/best_weights.pth'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66d0fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c5a7a8739c479dbad66f2714963a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f441937bd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i  = np.random.randint(len(samples))\n",
    "im = Image.open(os.path.join(samples.root, samples.path[i]))\n",
    "im = im.convert(mode='RGB')\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.subplot(1,3,1)\n",
    "\n",
    "imnp   = np.array(im)\n",
    "bbox   = samples.bbox[os.path.join('img', samples.gender[i], samples.cat[i], samples.id[i], samples.filename[i])][2:]\n",
    "width  = bbox[2] - bbox[0]\n",
    "height = bbox[3] - bbox[1]\n",
    "cv.rectangle(imnp, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255,0,0), 2)\n",
    "\n",
    "margin_x  = max((100-width) // 2, 0)\n",
    "margin_y  = max((100-height) // 2, 0)\n",
    "new_bbox  = [max(bbox[0]-margin_x,0), max(bbox[1]-margin_y,0), min(bbox[2]+margin_x,im.size[0]), min(bbox[3]+margin_y, im.size[1])]\n",
    "cv.rectangle(imnp, (new_bbox[0], new_bbox[1]), (new_bbox[2], new_bbox[3]), (0,255,0), 2)\n",
    "plt.imshow(imnp)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im.crop(bbox))\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(im.crop(new_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1c564aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WOMEN/Dresses', 'WOMEN/Skirts', 'WOMEN/Blouses_Shirts', 'MEN/Sweatshirts_Hoodies', 'WOMEN/Cardigans', 'WOMEN/Jackets_Coats', 'WOMEN/Sweaters', 'WOMEN/Tees_Tanks', 'WOMEN/Shorts', 'WOMEN/Rompers_Jumpsuits', 'WOMEN/Graphic_Tees', 'WOMEN/Pants', 'MEN/Shorts', 'MEN/Sweaters', 'MEN/Denim', 'MEN/Tees_Tanks', 'WOMEN/Sweatshirts_Hoodies', 'MEN/Pants', 'WOMEN/Denim', 'MEN/Jackets_Vests', 'WOMEN/Leggings', 'MEN/Shirts_Polos', 'MEN/Suiting']\n"
     ]
    }
   ],
   "source": [
    "proto_node_labels = list(samples.taxonomy.keys())\n",
    "proto_cat_labels  = []\n",
    "\n",
    "for label in proto_node_labels:\n",
    "    if len(label.split('/')) == 2:\n",
    "        proto_cat_labels.append(label)\n",
    "        \n",
    "proto_cat_embed = torch.stack([samples.taxonomy[label] for label in proto_cat_labels], dim=0).to(device)\n",
    "\n",
    "print(proto_cat_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814484e9",
   "metadata": {},
   "source": [
    "# Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d070362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:44<00:00,  3.46s/it]\n"
     ]
    }
   ],
   "source": [
    "true_cat_labels = []\n",
    "true_pid_labels = []\n",
    "pred_cat_labels = []\n",
    "\n",
    "metric = torch.ones(128).to(device)\n",
    "metric[-1] = -1\n",
    "\n",
    "total = 0\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for batch_dict in tqdm(loader):\n",
    "        batch_gender_idx = batch_dict['gender']\n",
    "        batch_cat_idx    = batch_dict['cat']\n",
    "        batch_pid_idx    = batch_dict['id']\n",
    "        batch_img        = batch_dict['img'].to(device)\n",
    "        \n",
    "        batch_embed = model(batch_img)\n",
    "        embeddings.append(batch_embed)\n",
    "        \n",
    "        distances = torch.acosh( -torch.matmul(metric * batch_embed, proto_cat_embed.transpose(1,0)) )\n",
    "        \n",
    "        pred_cat_idx = torch.argmin(distances, dim=1, keepdim=False)\n",
    "        \n",
    "        for i in range(pred_cat_idx.shape[0]):\n",
    "            pred_cat_label = proto_cat_labels[pred_cat_idx[i]]\n",
    "            true_cat_label = samples.voc['gender']._idx2word[batch_gender_idx[i].item()] + '/' + samples.voc['cat']._idx2word[batch_cat_idx[i].item()]\n",
    "            \n",
    "            true_cat_labels.append(true_cat_label)\n",
    "            pred_cat_labels.append(pred_cat_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6a346cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3013, 2.2784, 2.2992, 4.2808, 2.2778, 2.2811, 2.2828, 0.2809, 2.2814,\n",
       "        2.2798, 2.2742, 2.2816, 4.2812, 4.2807, 4.2804, 4.2833, 2.2772, 4.2810,\n",
       "        2.2766, 4.2806, 2.2755, 4.2808, 4.2800], device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3a02d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (%) : 77.98921661909293\n"
     ]
    }
   ],
   "source": [
    "acc = (np.array(true_cat_labels) == np.array(pred_cat_labels)).sum() / len(pred_cat_labels)\n",
    "\n",
    "print(\"Acc (%) : {}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4af9c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcb23f486a0431b840ae09ed74cfe01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "cm = confusion_matrix(true_cat_labels, pred_cat_labels, normalize='true', labels=proto_cat_labels)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in proto_cat_labels], columns = [i for i in proto_cat_labels])\n",
    "plt.figure(figsize = (12,9))\n",
    "\n",
    "sn.set(font_scale=.5)\n",
    "sn.heatmap(df_cm, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e11d39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "65acf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0398, 0.0554, 0.0594, 0.0620], grad_fn=<TopkBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871be2c03f4243bb9575e4ca5c4d49b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = 4\n",
    "i = np.random.randint(len(samples))\n",
    "out = samples[i]\n",
    "query_img = out[-2]\n",
    "\n",
    "img_tensor = samples.transforms(query_img).unsqueeze(0).to(device)\n",
    "img_embed  = model(img_tensor)\n",
    "\n",
    "scores = torch.acosh(-torch.matmul(metric * img_embed, pool.transpose(1,0))).cpu().squeeze()\n",
    "\n",
    "match_scores, match_idx = torch.topk(scores, K+1, largest=False)\n",
    "\n",
    "print(match_scores)\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(14,3))\n",
    "plt.subplot(1,K+1,1)\n",
    "plt.imshow(query_img)\n",
    "plt.axis('off')\n",
    "#plt.title(\"Query: \" + samples.voc['cat']._idx2word[cats[match_idx[0].item()]], fontsize=7)\n",
    "for i in range(K):\n",
    "    plt.subplot(1,K+1,i+2)\n",
    "    plt.imshow(samples[match_idx[i+1].item()][-2])\n",
    "    #plt.title(samples.voc['cat']._idx2word[cats[match_idx[i+1].item()]], fontsize=7)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db969ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tees_Tanks\n",
      "WOMEN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08240aeeacf442a5b32d1795ce6c26c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 223.5, 223.5, -0.5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.randint(len(samples))\n",
    "out = samples[i]\n",
    "print(out[1])\n",
    "print(out[0])\n",
    "plt.figure()\n",
    "plt.imshow(out[-2])\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
